---
title: "From logic to probability"
format:
  html:
    df-print: kable
    toc: true
execute: 
  warning: false
---

## Propositional logic

Propositional logic is a language used to represent knowledge and reason with statements that are either true or false (i.e., have a truth value; propositions).

Probability theory extends propositional logic to represent knowledge and reason with propositions that have an uncertain truth value (probability).

Inductive reasoning = reasoning with incomplete information.

## Propositional variables (aka atomic propositions)

These are statements that can either be true or false and do not have logical connectives. For example:

-   $P$: *It is raining*
-   $Q$: *The street is wet*

## Logical connectives (from atomic to compound propositions)

-   **AND** ($\land$): Conjunction, true iff both operands are true
-   **OR** ($\lor$): Disjunction, true iff at least one operand is true
-   **NOT** ($\lnot$): Negation, true iff the operand is false
-   **IMPLIES** ($\implies$): Implication, true iff the antecedent is false or the consequent is true
-   **IF AND ONLY IF** ($\iff$): Biconditional, true iff both operands are either true or false

## Truth tables

A tool used to determine the truth value of a compound proposition based on the truth values of the atomic propositions it is made of.

## Propositional logic

Propositional logic is a language used to represent knowledge and to reason about the truth or falsity of propositions based on their logical relationships within that knowledge.

A proposition is a statement that is either true or false. For example:

-   $P$: *It is raining*
-   $Q$: *The street is wet*

$P$ and $Q$ are atomic propositions.

They can be combined to form compound propositions.

Compound propositions are formed by combining atomic propositions using logical connectives.

The logical connectives are:

-   $\land$: and
-   $\lor$: or
-   $\neg$: not
-   $\implies$: implies (if-then)
-   $\iff$: if and only if

Logical connectives are defined by truth tables.

$$
\begin{array}{|c|c|c|c|c|c|c|c|}
\hline
P & Q & P \land Q & P \lor Q & \neg P & P \implies Q & \neg P \lor Q & P \iff Q \\
\hline
T & T & T & T & F & T & T & T \\
T & F & F & T & F & F & F & F \\
F & T & F & T & T & T & T & F \\
F & F & F & F & T & T & T & T \\
\hline
\end{array}
$$

$P \implies Q$ and $\lnot P \lor Q$ have the same truth table, i.e., they are logically equivalent:

$P \implies Q \equiv \lnot P \lor Q$

Logical implication ($P \implies Q$) simply indicates that if $P$ is true, then $Q$ must also be true. It does not imply any causal relationship between $P$ and $Q$.

For example, if:

-   $P$: *2 + 2 = 4*
-   $Q$: *All cats are mammals*

Then:

$P \implies Q$: If *2 + 2 = 4*, then *all cats are mammals*

is a true statement! It is also true in a world where *2 + 2 = 4* is false.

For example, if:

-   $P$: *A person has the APOE44 genotype*
-   $Q$: *A person has Alzheimer's disease*

Then:

$P \implies Q$: If *a person has the APOE44 genotype*, then *he/she has Alzheimer's disease*

is a true statement! It is also true in a world where a person does not have the APOE44 genotype.

## Truth tables in R

```{r}
#| output: false
library(tidyverse)
library(magrittr)
```

$S$ = sample space (all possible combinations of the truth values of all propositional variables)

```{r}
S = expand_grid(P = c(TRUE, FALSE), Q = c(TRUE, FALSE))

S
```

```{r}
S %>% mutate(
  P_AND_Q = P & Q,
  P_OR_Q = P | Q,
  NOT_P = !P,
  P_IMPLIES_Q = !P | Q,
  P_IFF_Q = (!P | Q) & (!Q | P))
```

## Arguments

$E$ = evidence/premises/knowledge base (see also background knowledge)

Assumption (major premise): *All man are mortal* (*if someone is a man, then he/she is mortal*)

Observation (minor premise): *Socrates is a man*

Conclusion: *Therefore, Socrates is mortal*

## Classical syllogism (deductive reasoning)

### Modus ponens

$$
\begin{array}{ll}
1. & P \implies Q \\
2. & P \\
\hline
\therefore & Q
\end{array}
$$

```{r}
S = expand_grid(P = c(TRUE, FALSE), Q = c(TRUE, FALSE))

S
```

```{r}
S %<>% mutate(
  P1 = !P | Q,
  P2 = P,
  E = P1 & P2,
  H = Q)

S
```

```{r}
S %<>% filter(E)

S
```

```{r}
S %>% pull(H) %>% mean()
```

### Modus tollens

$$
\begin{array}{ll}
1. & P \implies Q \\
2. & \lnot Q \\
\hline
\therefore & \lnot P
\end{array}
$$

```{r}
S = expand_grid(P = c(TRUE, FALSE), Q = c(TRUE, FALSE))

S
```

```{r}
S %<>% mutate(
  P1 = !P | Q,
  P2 = !Q,
  E = P1 & P2,
  H = !P)

S
```

```{r}
S %<>% filter(E)

S
```

```{r}
S %>% pull(H) %>% mean()
```

## Statistical syllogism (inductive reasoning)

### Affirming the consequent

$$
\begin{array}{ll}
1. & P \implies Q \\
2. & Q \\
\hline
\therefore & P
\end{array}
$$

```{r}
S = expand_grid(P = c(TRUE, FALSE), Q = c(TRUE, FALSE))

S
```

```{r}
S %<>% mutate(
  P_1 = !P | Q,
  P_2 = Q,
  E = P_1 & P_2,
  H = P)

S
```

```{r}
S %<>% filter(E)

S
```

```{r}
S %>% pull(H) %>% mean()
```

### Denying the antecedent

$$
\begin{array}{ll}
1. & P \implies Q \\
2. & \lnot P \\
\hline
\therefore & \lnot Q
\end{array}
$$

```{r}
S = expand_grid(P = c(TRUE, FALSE), Q = c(TRUE, FALSE))

S
```

```{r}
S %<>% mutate(
  P1 = !P | Q,
  P2 = !P,
  E = P1 & P2,
  H = !Q)

S
```

```{r}
S %<>% filter(E)

S
```

```{r}
S %>% pull(H) %>% mean()
```

## Urn with two balls

*An urn contains a white ball and a blue ball.*

*You draw one ball out.*

*What's the probability that you draw the white ball?*

$W$: *You draw the white ball.*

$B$: *You draw the blue ball.*

$P_1 = W \lor B$

$P_2 = \lnot (W \land B)$

$E = P_1 \land P_2$

$H = W$

$P(H \mid E)$

```{r}
S <- expand_grid(
  W = c(TRUE, FALSE),
  B = c(TRUE, FALSE))

S
```

```{r}
S %<>%
  mutate(
    P1 = (W | B),
    P2 = !(W & B),
    E = P1 & P2,
    H = W)

S
```

```{r}
S %<>% filter(E)

S
```

```{r}
S %>% pull(H) %>% mean()
```

## Urn with three balls

Background knowledge:

-   *An urn contains a two white balls and a blue ball.*

-   *You draw one ball out.*

-   *What's the probability that you draw a white ball?*

$W_1$: *You draw white ball #1.*

$W_2$: *You draw white ball #2.*

$B$: *You draw the blue ball.*

$P_1 = W_1 \lor W_2 \lor B$

$P_2 = \lnot (W_1 \land B)$

$P_3 = \lnot (W_2 \land B)$

$P_4 = \lnot (W_1 \land W_2)$

$E = P_1 \land P_2 \land P_3 \land P_4$

$H = W_1 \lor W_2$

$P(H \mid E)$

```{r}
S <- expand_grid(
  W1 = c(TRUE, FALSE),
  W2 = c(TRUE, FALSE),
  B = c(TRUE, FALSE))

S
```

```{r}
S %<>%
  mutate(
    P1 = (W1 | W2 | B),
    P2 = !(W1 & B),
    P3 = !(W2 & B),
    P4 = !(W1 & W2),
    E = P1 & P2 & P3 & P4,
    H = W1 | W2)

S
```

```{r}
S %<>% filter(E)

S
```

```{r}
S %>% pull(H) %>% mean()
```

## Urn with N balls

Background knowledge:

-   *Urn with N balls, M of which are white and N-M blue*.

-   *You draw one ball out.*

-   *What's the probability that you draw a white ball?*

$P(H \mid E) = \frac{M}{N}$

## Probability distributions

### Binomial

Given:

-   $E_B$: Binomial evidence

-   $K$: Number of successes

-   $N$: Number of trials

-   The probability of $K$ successes given the binomial evidence and number of trials can be written as:

$$
P(K = k \mid \Pi = \pi, N = n, E_B) = \binom{n}{k} \pi^k (1 - \pi)^{n - k}
$$

where:

-   $\binom{n}{k}$ is the binomial coefficient, which represents the number of ways to choose $k$ successes out of $n$ trials.

-   $p$ is the probability of success on a single trial.

Here is the R code to compute this probability:

```{r}
# Number of successes
k <- 3

# Number of trials
n <- 10

# Probability of success on a single trial
p <- 0.5

# Compute the binomial coefficient
binom_coeff <- choose(n, k)

# Compute the probability
probability <- binom_coeff * p^k * (1 - p)^(n - k)

# Print the result
probability
```

```{r}
S <- expand_grid(
  X1 = c(TRUE, FALSE),
  X2 = c(TRUE, FALSE),
  X3 = c(TRUE, FALSE),
  X4 = c(TRUE, FALSE),
  X5 = c(TRUE, FALSE),
  X6 = c(TRUE, FALSE),
  X7 = c(TRUE, FALSE),
  X8 = c(TRUE, FALSE),
  X9 = c(TRUE, FALSE),
  X10 = c(TRUE, FALSE))

S
```

```{r}
S %<>%
  mutate(K = pmap_int(., sum))

S
```

```{r}
S %>% mutate(H = K == 3) %>% pull(H) %>% mean()
```

```{r}
# Define parameters
n <- 10  # number of trials
p <- 0.5  # probability of success
k <- 3 # Hypothesis: exactly k successes

# Step 1: Generate all possible outcomes (truth table)
trials <- expand.grid(rep(list(c(TRUE, FALSE)), n))
colnames(trials) <- paste0("T", 1:n)

# Step 2: Calculate the probability of each outcome
# Function to calculate the probability of a specific outcome
calculate_probability <- function(row, p) {
  success_prob <- p ^ sum(row)  # Probability of successes
  failure_prob <- (1 - p) ^ (length(row) - sum(row))  # Probability of failures
  return(success_prob * failure_prob)
}

# Add a column for the probability of each outcome
trials$Probability <- apply(trials, 1, calculate_probability, p = p)

# Step 3: Specify the binomial evidence (number of successes)
count_successes <- function(row) {
  sum(row)
}

# Add a column for the number of successes
trials$Successes <- apply(trials, 1, count_successes)

# Step 4: Derive the probability of the hypothesis (e.g., exactly k successes)

# Filter for rows that match the hypothesis
matching_rows <- trials %>% filter(Successes == k)

# Calculate the probability of the hypothesis
probability <- sum(matching_rows$Probability)

# Print results
print(trials)
print(paste("Probability of exactly", k, "successes:", probability))

# Visualize the binomial distribution
barplot(table(trials$Successes) / nrow(trials), 
        names.arg = 0:n, 
        xlab = "Number of successes", 
        ylab = "Probability",
        main = paste("Binomial Distribution (n =", n, ", p =", p, ")"), 
        col = "blue")
```

## References

-   [Aubrey Clayton - One Probability to Rule them All?](https://youtu.be/HCG57e7Ogv8)

-   [Probability Theory: The Logic of Science Chapter 1, "Plausible reasoning"](https://youtu.be/P6P_1rjJuD_M?si=nkbx5j1PYwqOgK-V)

-   [Cox's theorem](https://en.wikipedia.org/wiki/Cox%27s_theorem) (Wikipedia)

-   [A little more information about Cox's theorem](https://youtu.be/o7Upwyn12IQ)

-   [Constructing a logic of plausible inference: a guide to Coxâ€™s theorem](https://www.sciencedirect.com/science/article/pii/S0888613X03000513)
